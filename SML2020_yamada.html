<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="publication.html">Publications</a></div>
<div class="menu-item"><a href="members.html">Members</a></div>
<div class="menu-item"><a href="software.html">Softwares</a></div>
</td>
<td id="layout-content">
<p><br /></p>
<h1>Statistical Learning Theory (2019), Graduate School of Informatics, Kyoto University</h1>
<p>Lectures: Hisashi Kashima and <a href="http://www.makotoyamada-ml.com/" target=&ldquo;blank&rdquo;>Makoto Yamada</a></p>
<p>This course will cover in a broad sense the fundamental theoretical aspects and applicative possibilities of statistical machine learning, which is now a fundamental block of statistical data analysis and data mining. This course will focus first on the supervised and unsupervised learning problems, including a survey of probably approximately correct learning, Bayesian learning as well as other learning theory frameworks. Following this introduction, several probabilistic models and prediction algorithms, such as the logistic regression, perceptron, and support vector machine will be introduced. Advanced topic such as online learning, structured prediction, and sparse modeling will be also introduced. </p>
<h2>Topics</h2>
<ul>
<li><p>Supervised learning and unsupervised learning</p>
</li>
<li><p>Linear and non-linear regression</p>
</li>
<li><p>Support vector machine and logistic regression</p>
</li>
<li><p>Learning theory</p>
</li>
<li><p>On-line learning</p>
</li>
<li><p>Model evaluation</p>
</li>
<li><p>Sparse modeling</p>
</li>
<li><p>Advanced topics (Semi-supervised learning, active learning, and structured output prediction)</p>
</li>
</ul>
<h2>Lecture Slides</h2>
<ol>
<li><p><a href="Course/2020/Feature_Selection_and_Sparsity.pdf" target=&ldquo;blank&rdquo;>Feature Selection and Sparsity</a></p>
</li>
<li><p><a href="Course/2020/Dimensionality_reduction.pdf" target=&ldquo;blank&rdquo;>Dimensionality Reduction</a>

</p>
</li>
<li><p><a href="Course/2020/Semi_supervised_Learning.pdf" target=&ldquo;blank&rdquo;>Semi-supervised Learning/Transfer Learning</a></p>
</li>
<li><p><a href="Course/2020/Model_Ensemble.pdf" target=&ldquo;blank&rdquo;>Model Ensemble</a></p>
</li>
<li><p><a href="Course/2020/Graph_Neural_Network.pdf" target=&ldquo;blank&rdquo;>Graph Neural Network</a>
</p>
</li>
</ol>
<div id="footer">
<div id="footer-text">
Page generated 2020-10-02 09:30:43 JST, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
(<a href="SML2020_yamada.jemdoc">source</a>)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
